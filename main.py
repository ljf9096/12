import urllib.request
from urllib.parse import urlparse
import re
from datetime import datetime, timedelta, timezone
from collections import defaultdict

class TVChannelProcessor:
    def __init__(self):
        self.timestart = datetime.now()
        self.blacklist = set()
        self.channel_sources = defaultdict(list)
        self.output_lines = []
        
        # åˆå§‹åŒ–é¢‘é“å®¹å™¨
        self.channel_containers = {
            'ys': [], 'ws': [], 'ty': [], 'dy': [], 'dsj': [],
            'gat': [], 'twt': [], 'gj': [], 'jlp': [], 'xq': [],
            'js': [], 'newtv': [], 'ihot': [], 'et': [], 'zy': [],
            'mdd': [], 'yy': [], 'game': [], 'radio': [], 'zb': [],
            'cw': [], 'mtv': [], 'migu': [], 'other': []
        }
        
        self.removal_patterns = [
            "ã€ŒIPV4ã€", "ã€ŒIPV6ã€", "[ipv6]", "[ipv4]", "_ç”µä¿¡", "ç”µä¿¡",
            "ï¼ˆHDï¼‰", "[è¶…æ¸…]", "é«˜æ¸…", "è¶…æ¸…", "-HD", "(HK)", "AKtv",
            "@", "IPV6", "ğŸï¸", "ğŸ¦", " ", "[BD]", "[VGA]", "[HD]",
            "[SD]", "(1080p)", "(720p)", "(480p)"
        ]

    def load_file(self, file_path: str) -> List[str]:
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return [line.strip() for line in f if line.strip()]
        except Exception as e:
            print(f"Error loading {file_path}: {e}")
            return []

    def process_channel(self, line: str):
        if not line or "#genre#" in line:
            return
            
        try:
            parts = line.split(',')
            if len(parts) == 3 and parts[0].endswith('ms'):
                time_ms = float(parts[0].replace('ms', ''))
                name = parts[1].strip()
                url = parts[2].strip()
            elif len(parts) >= 2:
                time_ms = float('inf')
                name = parts[0].strip()
                url = parts[1].strip()
            else:
                return
                
            # æ¸…ç†é¢‘é“åç§°
            for pattern in self.removal_patterns:
                name = name.replace(pattern, "")
                
            # å­˜å‚¨æºä¿¡æ¯
            if url not in self.blacklist:
                self.channel_sources[name].append((time_ms, url))
                
        except Exception as e:
            print(f"Error processing line: {e}")

    def select_top_sources(self, top_n=5):
        for name, sources in self.channel_sources.items():
            # æŒ‰å“åº”æ—¶é—´æ’åºå¹¶é€‰æ‹©å‰Nä¸ª
            sorted_sources = sorted(sources, key=lambda x: x[0])[:top_n]
            # æ·»åŠ åˆ°å¯¹åº”åˆ†ç±»
            container = self.get_channel_container(name)
            for _, url in sorted_sources:
                container.append(f"{name},{url}")

    def get_channel_container(self, name: str) -> List[str]:
        # è¿™é‡Œåº”è¯¥æœ‰å®é™…çš„é¢‘é“åˆ†ç±»é€»è¾‘
        # ç®€åŒ–ç‰ˆç›´æ¥æ”¾å…¥other
        return self.channel_containers['other']

    def generate_output(self):
        utc_time = datetime.now(timezone.utc)
        beijing_time = utc_time + timedelta(hours=8)
        version = beijing_time.strftime("%Y%m%d %H:%M")
        
        self.output_lines.append(f"æ›´æ–°æ—¶é—´,#genre#\n{version}")
        
        # æ·»åŠ å„åˆ†ç±»é¢‘é“
        for category, lines in self.channel_containers.items():
            if lines:
                self.output_lines.append(f"\n{category},#genre#")
                self.output_lines.extend(lines)

    def save_to_file(self, filename="live.txt"):
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write('\n'.join(self.output_lines))
            print(f"æ–‡ä»¶å·²ä¿å­˜: {filename}")
        except Exception as e:
            print(f"ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")

    def run(self):
        # åŠ è½½é»‘åå•
        self.blacklist = set(self.load_file('blacklist_auto.txt'))
        
        # åŠ è½½ç™½åå•å¹¶å¤„ç†
        whitelist = self.load_file('whitelist_auto.txt')
        for line in whitelist:
            self.process_channel(line)
            
        # å¤„ç†URLæº
        urls = self.load_file('urls.txt')
        for url in urls:
            if url.startswith('http'):
                self.process_url(url)
                
        # é€‰æ‹©æœ€ä½³æº
        self.select_top_sources()
        
        # ç”Ÿæˆè¾“å‡º
        self.generate_output()
        self.save_to_file()
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        total_sources = sum(len(sources) for sources in self.channel_sources.values())
        print(f"å¤„ç†å®Œæˆï¼Œå…±æ”¶é›† {total_sources} ä¸ªç›´æ’­æº")

    def process_url(self, url: str):
        try:
            with urllib.request.urlopen(url, timeout=10) as response:
                content = response.read().decode('utf-8')
                for line in content.splitlines():
                    self.process_channel(line)
        except Exception as e:
            print(f"å¤„ç†URLå¤±è´¥ {url}: {e}")

if __name__ == "__main__":
    processor = TVChannelProcessor()
    processor.run()
