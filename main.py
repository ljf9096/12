import urllib.request
from urllib.parse import urlparse
import re
import os
from datetime import datetime, timedelta, timezone
from collections import defaultdict
from typing import List, Set, Dict, Tuple
import opencc

class TVChannelProcessor:
    def __init__(self):
        self.timestart = datetime.now()
        self.combined_blacklist = set()
        self.all_urls = set()
        self.channel_sources = defaultdict(list)  # å­˜å‚¨é¢‘é“æºåŠå…¶å“åº”æ—¶é—´
        
        # åˆå§‹åŒ–é¢‘é“å®¹å™¨
        self.ys_lines = []  # å¤®è§†é¢‘é“
        self.ws_lines = []  # å«è§†é¢‘é“
        self.newtv_lines = []  # NewTVé¢‘é“
        
        self.removal_list = ["ã€ŒIPV4ã€","ã€ŒIPV6ã€","[ipv6]","[ipv4]","_ç”µä¿¡", "ç”µä¿¡",
                           "ï¼ˆHDï¼‰","[è¶…æ¸…]","é«˜æ¸…","è¶…æ¸…", "-HD","(HK)","AKtv","@",
                           "IPV6","ğŸï¸","ğŸ¦"," ","[BD]","[VGA]","[HD]","[SD]",
                           "(1080p)","(720p)","(480p)"]

    def read_txt_to_array(self, file_name: str) -> List[str]:
        """è¯»å–æ–‡æœ¬æ–‡ä»¶åˆ°æ•°ç»„"""
        try:
            with open(file_name, 'r', encoding='utf-8') as file:
                return [line.strip() for line in file if line.strip()]
        except Exception as e:
            print(f"è¯»å–æ–‡ä»¶é”™è¯¯ {file_name}: {e}")
            return []

    def load_corrections_name(self, filename: str) -> Dict[str, str]:
        """åŠ è½½é¢‘é“åç§°ä¿®æ­£"""
        corrections = {}
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        parts = line.strip().split(',')
                        if len(parts) >= 2:
                            correct_name = parts[0]
                            for name in parts[1:]:
                                corrections[name] = correct_name
        except Exception as e:
            print(f"åŠ è½½ä¿®æ­£æ–‡ä»¶é”™è¯¯: {e}")
        return corrections

    def clean_channel_name(self, name: str) -> str:
        """æ¸…ç†é¢‘é“åç§°"""
        for pattern in self.removal_list:
            name = name.replace(pattern, "")
            
        replacements = {
            "CCTV-": "CCTV", "CCTV0": "CCTV",
            "PLUS": "+", "NewTV-": "NewTV",
            "iHOT-": "iHOT", "NEW": "New",
            "New_": "New"
        }
        
        for old, new in replacements.items():
            name = name.replace(old, new)
            
        return name.strip()

    def clean_url(self, url: str) -> str:
        """æ¸…ç†URL"""
        return url.split('$')[0].strip()

    def add_channel_source(self, name: str, url: str, response_time: float = 9999.0):
        """æ·»åŠ é¢‘é“æºï¼Œæ¯ä¸ªé¢‘é“æœ€å¤šä¿ç•™5ä¸ªæœ€å¿«çš„æº"""
        if not url or url in self.combined_blacklist or url in self.all_urls:
            return
            
        self.all_urls.add(url)
        self.channel_sources[name].append((response_time, url))
        
        # æŒ‰å“åº”æ—¶é—´æ’åºå¹¶ä¿ç•™å‰5ä¸ª
        self.channel_sources[name].sort(key=lambda x: x[0])
        if len(self.channel_sources[name]) > 5:
            self.channel_sources[name] = self.channel_sources[name][:5]

    def process_line(self, line: str):
        """å¤„ç†å•è¡Œæ•°æ®"""
        if "#genre#" in line or "#EXTINF:" in line or "://" not in line:
            return
            
        try:
            # å¤„ç†æ™®é€šè¡Œ (é¢‘é“åç§°,URL)
            if line.count(',') == 1:
                name, url = line.split(',', 1)
                self.add_channel_source(
                    self.clean_channel_name(name.strip()),
                    self.clean_url(url.strip())
                )
            # å¤„ç†å¸¦å“åº”æ—¶é—´çš„è¡Œ (å“åº”æ—¶é—´,é¢‘é“åç§°,URL)
            elif line.count(',') >= 2:
                parts = line.split(',', 2)
                try:
                    time_ms = float(parts[0].replace("ms", "").strip())
                    if time_ms < 2000:  # åªä¿ç•™2ç§’å†…çš„æº
                        self.add_channel_source(
                            self.clean_channel_name(parts[1].strip()),
                            self.clean_url(parts[2].strip()),
                            time_ms
                        )
                except ValueError:
                    pass
                    
        except Exception as e:
            print(f"å¤„ç†è¡Œé”™è¯¯: {line}, é”™è¯¯: {e}")

    def download_and_process(self, url: str):
        """ä¸‹è½½å¹¶å¤„ç†URLå†…å®¹"""
        try:
            headers = {'User-Agent': 'Mozilla/5.0'}
            req = urllib.request.Request(url, headers=headers)
            
            with urllib.request.urlopen(req, timeout=15) as response:
                content = response.read()
                
                # å°è¯•ä¸åŒç¼–ç 
                for encoding in ['utf-8', 'gbk', 'gb2312']:
                    try:
                        text = content.decode(encoding)
                        # å¤„ç†M3Uæ ¼å¼
                        if text.strip().startswith("#EXTM3U"):
                            text = self.convert_m3u_to_txt(text)
                        
                        # å¤„ç†æ¯ä¸€è¡Œ
                        for line in text.splitlines():
                            self.process_line(line.strip())
                        break
                    except UnicodeDecodeError:
                        continue
                        
        except Exception as e:
            print(f"å¤„ç†URLé”™è¯¯ {url}: {e}")

    def convert_m3u_to_txt(self, m3u_content: str) -> str:
        """è½¬æ¢M3Uä¸ºTXTæ ¼å¼"""
        lines = []
        current_name = ""
        
        for line in m3u_content.split('\n'):
            line = line.strip()
            if line.startswith("#EXTINF"):
                parts = line.split(',', 1)
                if len(parts) > 1:
                    current_name = parts[1]
            elif line.startswith(("http://", "https://", "rtmp://")):
                if current_name:
                    lines.append(f"{current_name},{line}")
                    current_name = ""
        
        return '\n'.join(lines)

    def categorize_channels(self):
        """å°†é¢‘é“åˆ†ç±»"""
        for name, sources in self.channel_sources.items():
            # å·²ç»æŒ‰å“åº”æ—¶é—´æ’åºï¼Œç›´æ¥å–å‰5ä¸ª
            for time_ms, url in sources[:5]:
                line = f"{name},{url}"
                
                if "CCTV" in name or "å¤®è§†" in name:
                    self.ys_lines.append(line)
                elif "å«è§†" in name:
                    self.ws_lines.append(line)
                elif "NewTV" in name.upper():
                    self.newtv_lines.append(line)

    def generate_live_txt(self):
        """ç”Ÿæˆlive.txtæ–‡ä»¶"""
        beijing_time = datetime.now(timezone.utc) + timedelta(hours=8)
        version = beijing_time.strftime("%Y%m%d %H:%M")
        
        content = [
            "æ›´æ–°æ—¶é—´,#genre#",
            version,
            "",
            "å¤®è§†é¢‘é“,#genre#",
            *self.ys_lines,
            "",
            "å«è§†é¢‘é“,#genre#",
            *self.ws_lines,
            "",
            "NewTVé¢‘é“,#genre#",
            *self.newtv_lines
        ]
        
        try:
            with open("live.txt", 'w', encoding='utf-8') as f:
                f.write('\n'.join(content))
            print("live.txt ç”ŸæˆæˆåŠŸ")
        except Exception as e:
            print(f"å†™å…¥live.txté”™è¯¯: {e}")

    def generate_m3u(self):
        """ç”ŸæˆM3Uæ–‡ä»¶"""
        try:
            m3u_content = ['#EXTM3U x-tvg-url="https://epg.112114.xyz/pp.xml.gz"']
            current_group = ""
            
            with open("live.txt", 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if not line:
                        continue
                    
                    if line.endswith("#genre#"):
                        current_group = line.replace(",#genre#", "")
                    elif ',' in line:
                        name, url = line.split(',', 1)
                        logo = f"https://epg.112114.xyz/logo/{name}.png"
                        m3u_content.extend([
                            f'#EXTINF:-1 tvg-name="{name}" tvg-logo="{logo}" group-title="{current_group}",{name}',
                            url
                        ])
            
            with open("live.m3u", 'w', encoding='utf-8') as f:
                f.write('\n'.join(m3u_content))
            print("live.m3u ç”ŸæˆæˆåŠŸ")
            
        except Exception as e:
            print(f"ç”ŸæˆM3Uæ–‡ä»¶é”™è¯¯: {e}")

    def run(self):
        """ä¸»è¿è¡Œå‡½æ•°"""
        print("å¼€å§‹å¤„ç†ç”µè§†é¢‘é“...")
        print("é…ç½®: åªä¿ç•™å¤®è§†é¢‘é“ã€å«è§†é¢‘é“ã€NewTVé¢‘é“")
        print("æ¯ä¸ªé¢‘é“åªä¿ç•™å“åº”æ—¶é—´æœ€å¿«çš„å‰5ä¸ªæº")
        
        # åŠ è½½é»‘åå•
        self.combined_blacklist = set(self.read_txt_to_array('blacklist_auto.txt'))
        
        # åŠ è½½ç™½åå•å¹¶å¤„ç†
        for line in self.read_txt_to_array('whitelist_auto.txt'):
            self.process_line(line)
        
        # å¤„ç†URLåˆ—è¡¨
        for url in self.read_txt_to_array('urls.txt'):
            if url.startswith('http'):
                self.download_and_process(url)
        
        # åˆ†ç±»é¢‘é“
        self.categorize_channels()
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶
        self.generate_live_txt()
        self.generate_m3u()
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        timeend = datetime.now()
        elapsed = timeend - self.timestart
        print(f"\nå¤„ç†å®Œæˆï¼Œè€—æ—¶: {elapsed.total_seconds():.1f}ç§’")
        print(f"å¤®è§†é¢‘é“: {len(self.ys_lines)}")
        print(f"å«è§†é¢‘é“: {len(self.ws_lines)}")
        print(f"NewTVé¢‘é“: {len(self.newtv_lines)}")
        print(f"æ€»é¢‘é“æ•°: {len(self.ys_lines) + len(self.ws_lines) + len(self.newtv_lines)}")

if __name__ == "__main__":
    TVChannelProcessor().run()
