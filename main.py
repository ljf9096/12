import urllib.request
from urllib.parse import urlparse
import re
import os
from datetime import datetime, timedelta, timezone
from collections import defaultdict
from typing import List, Set, Dict, Tuple, DefaultDict
import opencc

class TVChannelProcessor:
    def __init__(self):
        self.timestart = datetime.now()
        self.combined_blacklist = set()
        self.channel_sources = defaultdict(list)  # å­˜å‚¨æ¯ä¸ªé¢‘é“çš„æºåŠå…¶å“åº”æ—¶é—´
        self.all_urls = set()
        
        # åˆå§‹åŒ–é¢‘é“å®¹å™¨
        self.init_channel_containers()
        
    def init_channel_containers(self):
        # ä¸»é¢‘é“å®¹å™¨
        self.ys_lines = []  # å¤®è§†é¢‘é“
        self.ws_lines = []  # å«è§†é¢‘é“
        self.ty_lines = []  # ä½“è‚²é¢‘é“
        # ... å…¶ä»–é¢‘é“å®¹å™¨åˆå§‹åŒ–
        self.other_lines = []
        
        self.removal_list = ["ã€ŒIPV4ã€","ã€ŒIPV6ã€","[ipv6]","[ipv4]","_ç”µä¿¡", "ç”µä¿¡",
                           "ï¼ˆHDï¼‰","[è¶…æ¸…]","é«˜æ¸…","è¶…æ¸…", "-HD","(HK)","AKtv","@",
                           "IPV6","ğŸï¸","ğŸ¦"," ","[BD]","[VGA]","[HD]","[SD]",
                           "(1080p)","(720p)","(480p)"]

    def read_txt_to_array(self, file_name: str) -> List[str]:
        """è¯»å–æ–‡æœ¬æ–‡ä»¶åˆ°æ•°ç»„"""
        try:
            with open(file_name, 'r', encoding='utf-8') as file:
                return [line.strip() for line in file.readlines()]
        except Exception as e:
            print(f"è¯»å–æ–‡ä»¶é”™è¯¯ {file_name}: {e}")
            return []

    def process_channel_line(self, line: str):
        """å¤„ç†å•è¡Œé¢‘é“æ•°æ®"""
        if not line or "#genre#" in line or "#EXTINF:" in line:
            return
            
        try:
            parts = line.split(',')
            if len(parts) == 3 and parts[0].endswith('ms'):
                # æ ¼å¼: "200ms,é¢‘é“åç§°,URL"
                time_ms = float(parts[0].replace('ms', ''))
                name = parts[1].strip()
                url = parts[2].strip()
            elif len(parts) >= 2:
                # æ ¼å¼: "é¢‘é“åç§°,URL"
                time_ms = float('inf')  # æ— å“åº”æ—¶é—´æ•°æ®
                name = parts[0].strip()
                url = parts[1].strip()
            else:
                return
                
            # æ¸…ç†é¢‘é“åç§°
            name = self.clean_channel_name(name)
            url = self.clean_url(url)
            
            if url and url not in self.combined_blacklist and url not in self.all_urls:
                self.all_urls.add(url)
                self.channel_sources[name].append((time_ms, url))
                
        except Exception as e:
            print(f"å¤„ç†é¢‘é“è¡Œé”™è¯¯: {e}")

    def clean_channel_name(self, name: str) -> str:
        """æ¸…ç†é¢‘é“åç§°"""
        for pattern in self.removal_list:
            name = name.replace(pattern, "")
            
        replacements = {
            "CCTV-": "CCTV", "CCTV0": "CCTV",
            "PLUS": "+", "NewTV-": "NewTV",
            "iHOT-": "iHOT", "NEW": "New",
            "New_": "New"
        }
        
        for old, new in replacements.items():
            name = name.replace(old, new)
            
        return name.strip()

    def clean_url(self, url: str) -> str:
        """æ¸…ç†URL"""
        return url.split('$')[0].strip()

    def select_top_sources(self, top_n=5):
        """é€‰æ‹©æ¯ä¸ªé¢‘é“å“åº”æ—¶é—´æœ€å¿«çš„å‰Nä¸ªæº"""
        for name, sources in self.channel_sources.items():
            # æŒ‰å“åº”æ—¶é—´æ’åº (ä»å°åˆ°å¤§)
            sorted_sources = sorted(sources, key=lambda x: x[0])
            # å–å‰Nä¸ª
            top_sources = sorted_sources[:top_n]
            
            # æ·»åŠ åˆ°å¯¹åº”åˆ†ç±»
            for _, url in top_sources:
                line = f"{name},{url}"
                self.categorize_channel(name, line)

    def categorize_channel(self, name: str, line: str):
        """é¢‘é“åˆ†ç±»é€»è¾‘"""
        # è¿™é‡Œåº”è¯¥æœ‰å®é™…çš„åˆ†ç±»é€»è¾‘ï¼Œç®€åŒ–ç‰ˆç›´æ¥æ”¾å…¥other
        self.other_lines.append(line)

    def generate_output(self):
        """ç”Ÿæˆè¾“å‡ºå†…å®¹"""
        utc_time = datetime.now(timezone.utc)
        beijing_time = utc_time + timedelta(hours=8)
        version = beijing_time.strftime("%Y%m%d %H:%M")
        
        output_lines = [
            f"æ›´æ–°æ—¶é—´,#genre#\n{version}\n",
            "å¤®è§†é¢‘é“,#genre#"
        ]
        
        # æ·»åŠ å„åˆ†ç±»é¢‘é“
        if self.ys_lines:
            output_lines.extend(self.ys_lines)
            
        output_lines.append("\nå«è§†é¢‘é“,#genre#")
        if self.ws_lines:
            output_lines.extend(self.ws_lines)
            
        # æ·»åŠ å…¶ä»–é¢‘é“
        if self.other_lines:
            output_lines.append("\nå…¶ä»–é¢‘é“,#genre#")
            output_lines.extend(self.other_lines)
            
        return '\n'.join(output_lines)

    def make_m3u(self, txt_content: str, m3u_file: str):
        """ä»æ–‡æœ¬å†…å®¹ç”ŸæˆM3Uæ–‡ä»¶"""
        try:
            output = '#EXTM3U x-tvg-url="https://epg.112114.xyz/pp.xml.gz"\n'
            group = ""
            
            for line in txt_content.split('\n'):
                if not line or line.startswith("æ›´æ–°æ—¶é—´,#genre#"):
                    continue
                    
                if "#genre#" in line:
                    group = line.split(',')[0]
                    output += f'#EXTINF:-1 group-title="{group}",\n'
                else:
                    name, url = line.split(',', 1)
                    logo = f"https://epg.112114.xyz/logo/{name}.png"
                    output += f'#EXTINF:-1 tvg-name="{name}" tvg-logo="{logo}" group-title="{group}",{name}\n'
                    output += f"{url}\n"
            
            with open(m3u_file, 'w', encoding='utf-8') as f:
                f.write(output)
            print(f"M3Uæ–‡ä»¶å·²ç”Ÿæˆ: {m3u_file}")
                
        except Exception as e:
            print(f"ç”ŸæˆM3Uæ–‡ä»¶é”™è¯¯: {e}")

    def run(self):
        """ä¸»è¿è¡Œæ–¹æ³•"""
        # åŠ è½½é»‘åå•
        blacklist = self.read_txt_to_array('blacklist_auto.txt')
        self.combined_blacklist = set(blacklist)
        
        # åŠ è½½ç™½åå•å¹¶å¤„ç†
        whitelist = self.read_txt_to_array('whitelist_auto.txt')
        for line in whitelist:
            self.process_channel_line(line)
            
        # å¤„ç†URLæº
        urls = self.read_txt_to_array('urls.txt')
        for url in urls:
            if url.startswith('http'):
                self.process_url(url)
                
        # é€‰æ‹©æœ€ä½³æº
        self.select_top_sources()
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶
        output_content = self.generate_output()
        with open("live.txt", 'w', encoding='utf-8') as f:
            f.write(output_content)
            
        # ç”ŸæˆM3Uæ–‡ä»¶
        self.make_m3u(output_content, "live.m3u")
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        total_channels = len(self.channel_sources)
        total_sources = sum(len(sources) for sources in self.channel_sources.values())
        print(f"å¤„ç†å®Œæˆï¼Œå…±æ”¶é›† {total_channels} ä¸ªé¢‘é“ï¼Œ{total_sources} ä¸ªç›´æ’­æº")

    def process_url(self, url: str):
        """å¤„ç†URLè·å–ç›´æ’­æº"""
        try:
            headers = {'User-Agent': 'Mozilla/5.0'}
            req = urllib.request.Request(url, headers=headers)
            
            with urllib.request.urlopen(req, timeout=10) as response:
                content = response.read().decode('utf-8')
                for line in content.splitlines():
                    self.process_channel_line(line)
                    
        except Exception as e:
            print(f"å¤„ç†URLé”™è¯¯ {url}: {e}")

if __name__ == "__main__":
    processor = TVChannelProcessor()
    processor.run()
